## Redis 캐시 전략

캐시 읽기 전략(Read Cache Strategy)

### Cache Aside(Look Aside)
- 데이터를 찾을 때 우선 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략
- 만일 캐시에 데이터가 없으면 DB에서 조회함
- **반복적인 읽기가 많은 호출에 적합**
- 캐시와 DB가 분리되어 가용되므로, 원하는 데이터만 별도로 구성하여 캐시에 저장
- 캐시와 DB가 분리되어 가용되기 때문에 캐시 장애 대비 구성이 되어있음
- 만일 redis가 다운 되더라도 DB에서 데이터를 가져올 수 있어 서비스 자체는 문제가 없음
- 대신에 캐시에 붙어있던 connection이 많았다면, redis가 다운된 순간 순간적으로 DB로 몰려서 부하 발생


#### 문제점
1. 캐시에 장애가 발생하더라도 DB에 요청을 전달함으로써 캐시 장애로 인한 서비스 문제는 대비할 수 있지만,
캐시 저장소와 DB간 데이터 정합성 문제가 발생할 수 있음.
2. 초기 조회 시, 무조건 DB를 호출해야 하므로 단건 호출 빈도가 높은 서비스에 부적합. 반복적으로 동일 쿼리 수행하는 서비스에 적합한 아키텍처

#### Cache Warming
- 미리 cache로 db의 데이터를 밀어 넣어 두는 작업을 의미
- 이 작업을 수행하지 않으면 서비스 초기에 트래픽 급증 시 대량의 cache miss가 발생 할 수 있음

### Read Through 
- 캐시에서만 데이터를 읽음
- 데이터 동기화를 라이브러리 또는 캐시 제공자에게 위임
- 따라서 데이터를 조회하는데 있어 전체적으로 속도가 느림
-  또한 데이터 조회를 전적으로 캐시만 의존하므로, redis 다운 시 서비스 문제 발생
- 대신 캐시와 DB간의 데이터 동기화가 항상 유지되므로, 데이터 정합성 문제 발생하지 않음
- 이 방식 또한 서비스 운영 초반에 cache warming을 수행 권장

### write back cache

- 데이터를 저장할 때, DB에 바로 쿼리를 날리지 않고, 캐시에 모아서 배치 작업
- Write가 빈번하면서 Read를 하는데 많은 양의 Resource가 소모되는 서비스에 적합
- 데이터 정합성 확보
- 자주 사용되지 않는 불필요한 리소스 저장
- 캐시에서 오류가 발생하면 **데이터를 영구 소실**

장점: DB에 대한 쓰기 비용을 줄일 수 있다. (latency가 감소)
단점: 데이터의 일관성이 write through에 비해 떨어진다. 동시에 여러 클라이언트가 요청을 한다면 업데이트 이전 데이터를 가져올 수 있다. (다중서버에서 문제발생)



### Write Through
- 캐시와 DB 둘다 업데이트 하는 방식
- 데이터 저장 시 캐시 저장한 뒤 바로 DB 저장
- DB와 캐시가 항상 동기화 되어 있어, 캐시의 데이터는 항상 최신
- 캐시와 백업 저장소에 업데이트를 같이 하여 데이터 일관성 유지
- 데이터 유실이 발생하면 안 되는 상황에 적합
- 자주 사용되지 않는 불필요한 리소스 저장.
- 매 요청마다 두번의 Write가 발생하게 됨으로써 빈번한 생성, 수정이 발생하는 서비스에서 성능 이슈
- 기억장치 속도가 느리면, 데이터 기록할 때 CPU가 대기하는 시간이 필요하므로 성능 감소

#### write throuth, wirte back 단점
- 둘다 자주 사용되지 않는 데이터가 저장되어 리소스 낭비가 발생되는 문제점.
- 해결하기 위해 TTL을 꼭 사용하여 사용되지 않는 데이터는 반드시 삭제 (expire)


### write Around
- Wirte Through 보다 빠름
- 모든 데이터는 DB에 저장
- Cache miss가 발생하면 DB와 캐시에도 데이터를 저장
- 따라서 캐시와 DB 내의 데이터가 다를 수 있음, ex)게시물 조회 후 게시물 수정 후 다시 게시물 조회 시
- 대처방법으로 DB에 저장된 데이터가 수정,삭제될 때마다, Cache 또한 삭제하거나 변경해야하고, Cache의 expire를 짧개 조정하는 식으로 대처


## 캐시 공간 문제

### Cache Eviction
- 캐시 공간이 필요할 때 어떤 데이터를 지우는 것

캐시 서버는 속도를 위해 대부분 메모리를 사용하는데, 메모리는 용량이 작으므로 이 공간을 어떻게 효율적으로 공간을 확보할 것인지 중요함

### LRU(Least Recently Used)

- 캐시의 크기가 한계에 이르면, 사용된 지 오래된 순으로 제거

### LFU(Least Frequently Used)
- 캐시의 크기가 한계에 이르면, 사용된 빈도가 낮은 순으로 제거된다.


ref: https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC <br>
ref: https://hayeon17kim.github.io/posts/cache/
